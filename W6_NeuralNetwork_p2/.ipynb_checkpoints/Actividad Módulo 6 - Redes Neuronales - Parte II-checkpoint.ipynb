{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef5a4c2e-1082-4e49-91cd-c1ec2abb237e",
   "metadata": {},
   "source": [
    "# INTEGRANTES:\n",
    "#####            -GONZALO DANIEL GRECCO\n",
    "#####            -MAURICIO NICOL√ÅS MOLINA PICCO\n",
    "#####            -MAR√çA IN√âS BERDI√ëAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6b98d7",
   "metadata": {},
   "source": [
    "# M√≥dulo 6: Redes Neuronales - Parte II\n",
    "\n",
    "## Redes Neuronales para clasificaci√≥n multiclase\n",
    "\n",
    "En esta actividad vamos a aprender a desarrollar una red neuronal profunda para reconocimiento de im√°genes.\n",
    "\n",
    "Adem√°s, estudiaremos algunos detalles de implementaci√≥n que nos ayudar√°n a organizar mejor nuestro c√≥digo y hacerlo m√°s eficiente.\n",
    "\n",
    "Por otro lado, aprenderemos a utilizar **Callbacks** para detener el proceso de entrenamiento anticipadamente si se alcanza un objetivo deseado.\n",
    "\n",
    "Para ello, vamos a trabajar con un dataset provisto por Keras: **Fashion MNIST**. Este dataset consta de **70.000 im√°genes en escala de grises de 28x28 p√≠xeles**, pertenecientes a una de **10 clases de prendas de vestir** diferentes.\n",
    "\n",
    "El dataset est√° dividido en **60.000 im√°genes para entrenamiento y 10.000 para testeo**.\n",
    "\n",
    "Cada imagen representa una prenda de vestir de una de las siguientes categor√≠as:\n",
    "\n",
    "                                0. T-shirt/top\n",
    "                                1. Trouser\n",
    "                                2. Pullover\n",
    "                                3. Dress\n",
    "                                4. Coat\n",
    "                                5. Sandal\n",
    "                                6. Shirt\n",
    "                                7. Sneaker\n",
    "                                8. Bag\n",
    "                                9. Ankle boot \n",
    "\n",
    "Cada p√≠xel tiene un valor asociado entre 0 y 255 que indica su nivel de luminosidad u oscuridad (valores m√°s altos indican mayor oscuridad).\n",
    "\n",
    "El dataset tiene **785 columnas**, donde la primera corresponde al **label** (la categor√≠a de la prenda) y las 784 restantes representan los features, es decir, los valores de cada uno de los p√≠xeles de la imagen.\n",
    "\n",
    "La idea es utilizar este dataset para **reconocer prendas de vestir mediante una red neuronal profunda**, compuesta por varias capas (**layers**) y m√∫ltiples neuronas. Para ello, ser√° necesario definir un **modelo de clasificaci√≥n multiclase**.\n",
    "\n",
    "En primer lugar, vamos a **cargar el dataset en memoria**, dividi√©ndolo en conjunto de entrenamiento y conjunto de testeo, e imprimiremos sus dimensiones para confirmar que se haya cargado correctamente.\n",
    "\n",
    "\n",
    "### <font color='red'>**Actividad 1:**</font>\n",
    "**a)** Escribir un programa en Python para obtener, desde el framework Keras, **el dataset Fashion MNIST dividido en conjunto de entrenamiento (X_train, y_train) y conjunto de testeo (X_test, y_test)**.\n",
    "\n",
    "**AYUDA:** el dataset fashion_mnist se encuentra dentro de la libreria keras.datasets. Keras provee una forma de obtener el dataset dividido en entrenamiento y testeo con el m√©todo [.load_data() ](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_mnist/load_data#expandable-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4083004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "# Carga del dataset (ya dividido en train y test)\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "#Carga el dataset. load_data() devuelve dos tuplas: la primera (X_train, y_train) para entrenamiento y la segunda (X_test, y_test) para testeo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c8ec82",
   "metadata": {},
   "source": [
    "**b)** Imprimir las **dimensiones** de todos los datasets (X_train, y_train, X_test, y test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7516835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Dimensiones (shapes) ---\n",
      "X_train.shape: (60000, 28, 28)\n",
      "y_train.shape: (60000,)\n",
      "X_test.shape:  (10000, 28, 28)\n",
      "y_test.shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Dimensiones (shapes) ---\")\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "print(\"X_test.shape: \", X_test.shape)\n",
    "print(\"y_test.shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f7b640-217c-4102-9e1d-bbf53a3a8054",
   "metadata": {},
   "source": [
    "### El resultado de shape de X es (60000,28,28) significa que son:\n",
    "- 60000 muestras (imagenes)\n",
    "- 28x28 tamanio de imagenes\n",
    "- la otra dimension no se muestra porque es 1 (1 dimension para color) pero si fuera rgb tendria otra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7d6ad7",
   "metadata": {},
   "source": [
    "### <font color='red'>**Actividad 2:**</font>\n",
    "**a)** Imprimir dos im√°genes cualquiera utilizando la librer√≠a **matplotlib**.\n",
    "\n",
    "**AYUDA:** Recordemos que para imprimir una imagen con matplotlib se puede utilizar el metodo [.imshow(image)](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html#matplotlib-pyplot-imshow), siendo image el vector que contiene los 784 pixeles de la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "56a5d318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt #matplotlib es la biblioteca de graficos \n",
    "\n",
    "# Mostrar la primera imagen de entrenamiento\n",
    "plt.subplot(1, 2, 1)                # 1 fila, 2 columnas, primer gr√°fico\n",
    "plt.imshow(X_train[0], cmap=\"gray\") # X_train[0] es una matriz 28x28\n",
    "plt.title(f\"Etiqueta: {y_train[0]}\")\n",
    "plt.axis(\"off\")                     \n",
    "#plt.axis(\"off\") quita los ejes para que se vea m√°s limpio\n",
    "\n",
    "# Mostrar la segunda imagen de entrenamiento\n",
    "plt.subplot(1, 2, 2)                # 1 fila, 2 columnas, segundo gr√°fico\n",
    "plt.imshow(X_train[1], cmap=\"gray\") # X_train[1] es otra imagen\n",
    "plt.title(f\"Etiqueta: {y_train[1]}\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f20b58",
   "metadata": {},
   "source": [
    "### <font color='red'>**Actividad 3:**</font>\n",
    "**a)** **Normalizar los valores de los features** en los datasets de entrenamiento y testeo (X_train y X_test) dividiendo los valores de los pixeles por 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c828b4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rango X_train: min = 0.0 , max = 1.0\n",
      "Rango X_test:  min = 0.0 , max = 1.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Los p√≠xeles en Fashion MNIST van de 0 a 255 (uint8).\n",
    "Al dividir entre 255, los llevamos al rango [0, 1], lo que hace que el entrenamiento sea m√°s estable y eficiente.\n",
    "\"\"\"\n",
    "#astype(\"float32\") convierte los pixeles enteros a n√∫meros decimales\n",
    "X_train = X_train.astype(\"float32\") / 255.0 \n",
    "X_test  = X_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Verificamos resultados\n",
    "print(\"Rango X_train: min =\", X_train.min(), \", max =\", X_train.max())\n",
    "print(\"Rango X_test:  min =\", X_test.min(),  \", max =\", X_test.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6993e0b",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "\n",
    "Los Callbacks de Keras son objetos que ejecutan acciones en distintas etapas del proceso de entrenamiento (por ejemplo, al comienzo o al final de cada epoch). Generalmente, se utilizan para escribir registros (logs) de monitoreo, guardar el modelo en disco peri√≥dicamente, detener el entrenamiento anticipadamente, entre otras funciones.\n",
    "\n",
    "El siguiente c√≥digo muestra c√≥mo crear un Callback personalizado en TensorFlow/Keras que detiene el entrenamiento cuando se alcanza un valor m√°ximo de precisi√≥n definido previamente:\n",
    "\n",
    "```\n",
    "class callbacks(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get(\"accuracy\") > MAX_ACC:\n",
    "            self.model.stop_training = True\n",
    "```\n",
    "\n",
    "Este tipo de callback se pasa como par√°metro al m√©todo .fit() mediante el argumento callbacks.\n",
    "\n",
    "### <font color='red'>**Actividad 4:**</font>\n",
    "**a)** Crear una clase **Callback** que detenga el proceso de entrenamiento al finalizar un epoch si se alcanza un valor de accuracy igual o superior a 0.95, e imprima el siguiente mensaje de aviso:\n",
    "\n",
    "\t‚ÄúSe alcanz√≥ el m√°ximo de precisi√≥n y, por lo tanto, se cancel√≥ el proceso de entrenamiento.‚Äù\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "bf9cac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Definici√≥n de Callback personalizado\n",
    "class EarlyStopAtAcc(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        acc = logs.get(\"accuracy\")\n",
    "        if acc is not None and acc >= 0.95:\n",
    "            print(\"\\nSe alcanz√≥ el m√°ximo de precisi√≥n y, por lo tanto, se cancel√≥ el proceso de entrenamiento.\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5cf506",
   "metadata": {},
   "source": [
    "### Ordenando el c√≥digo\n",
    "Ahora que tenemos los datasets de entrenamiento y testeo normalizados, y hemos observado algunos ejemplos, vamos a crear el modelo, compilarlo y entrenarlo.\n",
    "\n",
    "Para ello, definiremos un m√©todo que re√∫na todo el proceso completo:\n",
    "1. Obtener el dataset de entrenamiento y de testeo (resuelto en Actividad 1.a.)\n",
    "2. Normalizar los features de entrenamiento y testeo (resuelto en Actividad 3.)\n",
    "3. Crear el modelo en Keras\n",
    "4. Compilar el modelo (.compile(...))\n",
    "5. Ajustar o entrenar (.fit(...)) el modelo pasandole el callback creado y almacenando el historial del proceso de entrenamiento.\n",
    "6. Retornar el historial del proceso de entrenamiento y el modelo creado.\n",
    "\n",
    "#### üîß Creaci√≥n del modelo\n",
    "\n",
    "Vamos a construir una red neuronal con cuatro capas ocultas:\n",
    "- La primera con **512 neuronas**,\n",
    "- La segunda con **256 neuronas**,\n",
    "- La tercera con **128 neuronas**,\n",
    "- La cuarta con **64 neuronas**.\n",
    "\n",
    "Como se trata de un problema de **clasificaci√≥n multiclase**, al final del modelo utilizaremos la funci√≥n de activaci√≥n **softmax**. Sin embargo, implementaremos la **versi√≥n mejorada** vista en el apunte: la √∫ltima capa tendr√° activaci√≥n **lineal**, y la funci√≥n **softmax** se aplicar√° luego, por fuera del modelo.\n",
    "\n",
    "Adem√°s, como estamos trabajando con im√°genes, la primera capa de nuestra red debe ser una capa Flatten(), que transforma cada imagen 28x28 en un vector de 784 elementos.\n",
    "\n",
    "#### ‚öôÔ∏è Compilaci√≥n del modelo\n",
    "\n",
    "Al compilar el modelo:\n",
    "- Usaremos el optimizador **Adam** (optimizer='adam')\n",
    "- Como m√©trica de evaluaci√≥n, emplearemos **accuracy** (metrics=['accuracy'])\n",
    "- Usaremos *SparseCategoricalCrossentropy(from_logits=True)* como funci√≥n de p√©rdida ya que estamos utilizando logits como salida (activaci√≥n lineal en la √∫ltima capa)\n",
    "\n",
    "#### üèãÔ∏è Entrenamiento del modelo\n",
    "\n",
    "Al entrenar el modelo con .fit(), le pasaremos:\n",
    "- Le pasaremos el **callback personalizado** creado anteriormente (callbacks=[myCallback])\n",
    "- Definiremos la cantidad de **epochs en 100** (epochs=100)\n",
    "\n",
    "#### üìà Historial del entrenamiento\n",
    "\n",
    "El historial del proceso es devuelto por el m√©todo .fit() como un objeto History. Este objeto guarda, en su atributo .history, los registros de los valores de error y las m√©tricas obtenidas en cada epoch.\n",
    "\n",
    "\n",
    "### <font color='red'>**Actividad 5:**</font>\n",
    "**a)** Crear un m√©todo llamado train_fashion_mnist() que englobe los seis pasos mencionados anteriormente. Notar que algunos de estos pasos ya fueron resueltos en ejercicios anteriores, por lo tanto, simplemente debemos **copiar las l√≠neas de c√≥digo correspondientes dentro de este nuevo m√©todo** para integrarlos al flujo completo de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fde0f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.nn import softmax\n",
    "\n",
    "# Callback personalizado que detiene el entrenamiento al alcanzar 95% de accuracy\n",
    "class EarlyStopAtAcc(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        acc = logs.get(\"accuracy\")\n",
    "        if acc is not None and acc >= 0.95:\n",
    "            print(\"\\nSe alcanz√≥ el m√°ximo de precisi√≥n y, por lo tanto, se cancel√≥ el proceso de entrenamiento.\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "def train_fashion_mnist():\n",
    "\n",
    "    # Creamos un objeto de la clase callbacks creada anteriormente\n",
    "    myCallback = EarlyStopAtAcc()\n",
    "    \n",
    "    # 1. Obtener el dataset de entrenamiento y de testeo (resuelto en Ejercicio 1) a.)\n",
    "    (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "    \n",
    "    # 2. Normalizar los features de entrenamiento y testeo (resuelto en Ejercicio 3.)\n",
    "    X_train = X_train.astype(\"float32\") / 255.0\n",
    "    X_test  = X_test.astype(\"float32\") / 255.0\n",
    "    \n",
    "    # 3. Crear el modelo en Keras\n",
    "    model = models.Sequential([\n",
    "        layers.Flatten(input_shape=(28, 28)),   # Aplana la imagen 28x28 en vector 784\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Dense(256, activation=\"relu\"),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"linear\")   # salida lineal\n",
    "    ])\n",
    "    \n",
    "    # 4. Compilar el modelo (.compile(...))\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=SparseCategoricalCrossentropy(from_logits=True), \n",
    "        metrics=[\"accuracy\"]\n",
    "    ) #Cuando from_logits=True, Keras aplica internamente un softmax a los logits antes de calcular la entrop√≠a cruzada. De esta forma, no necesitamos poner activation=\"softmax\" dentro del modelo.\n",
    "    \n",
    "    # 5. Ajustar o entrenar (.fit(...)) el modelo pasandole el callback creado y almacenando el historial del proceso de entrenamiento.\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100,\n",
    "        callbacks=[myCallback],\n",
    "        validation_data=(X_test, y_test),\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # 6.Retornar el historial del proceso de entrenamiento.\n",
    "    return history.history, model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff64da4",
   "metadata": {},
   "source": [
    "Ahora que tenemos un m√©todo capaz de realizar todo el proceso completo, **lo √∫nico que resta es llamar a dicho m√©todo** para obtener el objeto history y el model.\n",
    "\n",
    "El entrenamiento deber√≠a finalizar aproximadamente en el **epoch 35**, si se alcanza el nivel de precisi√≥n definido en el callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "77794dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 - 9s - 5ms/step - accuracy: 0.8190 - loss: 0.4975 - val_accuracy: 0.8526 - val_loss: 0.4035\n",
      "Epoch 2/100\n",
      "1875/1875 - 8s - 4ms/step - accuracy: 0.8657 - loss: 0.3685 - val_accuracy: 0.8642 - val_loss: 0.3815\n",
      "Epoch 3/100\n",
      "1875/1875 - 8s - 4ms/step - accuracy: 0.8776 - loss: 0.3336 - val_accuracy: 0.8525 - val_loss: 0.4016\n",
      "Epoch 4/100\n",
      "1875/1875 - 8s - 4ms/step - accuracy: 0.8851 - loss: 0.3116 - val_accuracy: 0.8669 - val_loss: 0.3737\n",
      "Epoch 5/100\n",
      "1875/1875 - 8s - 4ms/step - accuracy: 0.8942 - loss: 0.2902 - val_accuracy: 0.8766 - val_loss: 0.3531\n",
      "Epoch 6/100\n",
      "1875/1875 - 7s - 4ms/step - accuracy: 0.8980 - loss: 0.2749 - val_accuracy: 0.8800 - val_loss: 0.3443\n",
      "Epoch 7/100\n",
      "1875/1875 - 8s - 4ms/step - accuracy: 0.9022 - loss: 0.2636 - val_accuracy: 0.8711 - val_loss: 0.3833\n",
      "Epoch 8/100\n",
      "1875/1875 - 7s - 4ms/step - accuracy: 0.9056 - loss: 0.2515 - val_accuracy: 0.8856 - val_loss: 0.3266\n",
      "Epoch 9/100\n",
      "1875/1875 - 8s - 4ms/step - accuracy: 0.9093 - loss: 0.2433 - val_accuracy: 0.8848 - val_loss: 0.3513\n",
      "Epoch 10/100\n",
      "1875/1875 - 7s - 4ms/step - accuracy: 0.9109 - loss: 0.2346 - val_accuracy: 0.8751 - val_loss: 0.3558\n",
      "Epoch 11/100\n",
      "1875/1875 - 7s - 4ms/step - accuracy: 0.9155 - loss: 0.2247 - val_accuracy: 0.8832 - val_loss: 0.3413\n",
      "Epoch 12/100\n",
      "1875/1875 - 7s - 4ms/step - accuracy: 0.9167 - loss: 0.2175 - val_accuracy: 0.8724 - val_loss: 0.3986\n",
      "Epoch 13/100\n",
      "1875/1875 - 8s - 4ms/step - accuracy: 0.9192 - loss: 0.2118 - val_accuracy: 0.8874 - val_loss: 0.3387\n",
      "Epoch 14/100\n",
      "1875/1875 - 7s - 4ms/step - accuracy: 0.9236 - loss: 0.2043 - val_accuracy: 0.8877 - val_loss: 0.3539\n",
      "Epoch 15/100\n",
      "1875/1875 - 7s - 4ms/step - accuracy: 0.9244 - loss: 0.1967 - val_accuracy: 0.8907 - val_loss: 0.3565\n",
      "Epoch 16/100\n",
      "1875/1875 - 8s - 4ms/step - accuracy: 0.9266 - loss: 0.1924 - val_accuracy: 0.8810 - val_loss: 0.3792\n",
      "Epoch 17/100\n",
      "1875/1875 - 7s - 4ms/step - accuracy: 0.9281 - loss: 0.1879 - val_accuracy: 0.8901 - val_loss: 0.3454\n",
      "Epoch 18/100\n",
      "1875/1875 - 8s - 4ms/step - accuracy: 0.9315 - loss: 0.1810 - val_accuracy: 0.8885 - val_loss: 0.3876\n",
      "Epoch 19/100\n",
      "1875/1875 - 9s - 5ms/step - accuracy: 0.9339 - loss: 0.1755 - val_accuracy: 0.8874 - val_loss: 0.3862\n",
      "Epoch 20/100\n",
      "1875/1875 - 8s - 4ms/step - accuracy: 0.9346 - loss: 0.1712 - val_accuracy: 0.8901 - val_loss: 0.3884\n",
      "Epoch 21/100\n",
      "1875/1875 - 7s - 4ms/step - accuracy: 0.9363 - loss: 0.1649 - val_accuracy: 0.8938 - val_loss: 0.3642\n",
      "Epoch 22/100\n",
      "1875/1875 - 8s - 4ms/step - accuracy: 0.9368 - loss: 0.1637 - val_accuracy: 0.8859 - val_loss: 0.4069\n",
      "Epoch 23/100\n",
      "1875/1875 - 8s - 4ms/step - accuracy: 0.9383 - loss: 0.1608 - val_accuracy: 0.8935 - val_loss: 0.3805\n",
      "Epoch 24/100\n",
      "1875/1875 - 8s - 4ms/step - accuracy: 0.9417 - loss: 0.1517 - val_accuracy: 0.8816 - val_loss: 0.4482\n",
      "Epoch 25/100\n",
      "1875/1875 - 7s - 4ms/step - accuracy: 0.9405 - loss: 0.1554 - val_accuracy: 0.8929 - val_loss: 0.3931\n",
      "Epoch 26/100\n",
      "1875/1875 - 10s - 5ms/step - accuracy: 0.9443 - loss: 0.1449 - val_accuracy: 0.8958 - val_loss: 0.4464\n",
      "Epoch 27/100\n",
      "1875/1875 - 8s - 4ms/step - accuracy: 0.9450 - loss: 0.1426 - val_accuracy: 0.8915 - val_loss: 0.4543\n",
      "Epoch 28/100\n",
      "1875/1875 - 8s - 4ms/step - accuracy: 0.9463 - loss: 0.1443 - val_accuracy: 0.8910 - val_loss: 0.4065\n",
      "Epoch 29/100\n",
      "1875/1875 - 8s - 4ms/step - accuracy: 0.9488 - loss: 0.1362 - val_accuracy: 0.8912 - val_loss: 0.4528\n",
      "Epoch 30/100\n",
      "1875/1875 - 8s - 4ms/step - accuracy: 0.9483 - loss: 0.1333 - val_accuracy: 0.8933 - val_loss: 0.4536\n",
      "Epoch 31/100\n",
      "1875/1875 - 8s - 4ms/step - accuracy: 0.9500 - loss: 0.1325 - val_accuracy: 0.8956 - val_loss: 0.4483\n",
      "Epoch 32/100\n",
      "\n",
      "Se alcanz√≥ el m√°ximo de precisi√≥n y, por lo tanto, se cancel√≥ el proceso de entrenamiento.\n",
      "1875/1875 - 7s - 4ms/step - accuracy: 0.9501 - loss: 0.1324 - val_accuracy: 0.8878 - val_loss: 0.5008\n"
     ]
    }
   ],
   "source": [
    "history, model = train_fashion_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ec3d74",
   "metadata": {},
   "source": [
    "Hay que tener en cuenta que, en el modelo creado, **a√∫n no se ha aplicado la funci√≥n softmax**, por lo que las salidas **no representan probabilidades**. Es decir, los valores de salida pueden estar en el rango **[-‚àû, +‚àû]**.\n",
    "\n",
    "A continuaci√≥n, vamos a observar los valores de salida para el **primer ejemplo** del conjunto de entrenamiento. Adem√°s, analizaremos **los valores m√°ximos y m√≠nimos** de todas las salidas para confirmar que **no se trata de probabilidades**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6aede106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 2ms/step\n",
      "Salidas sin softmax para el primer ejemplo:\n",
      "[-17.469152  -14.136044  -11.231507   -9.1872425 -14.566692   -6.5888705\n",
      " -14.489996    3.7524219 -10.131549    6.3474913]\n",
      "\n",
      "Valor m√°ximo entre todas las salidas: 186.93184\n",
      "Valor m√≠nimo entre todas las salidas: -1056.3743\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Obtener las salidas del modelo (logits) sin aplicar softmax\n",
    "train_logits = model.predict(X_train)\n",
    "\n",
    "# Mostrar los valores de salida para el primer ejemplo\n",
    "print(\"Salidas sin softmax para el primer ejemplo:\")\n",
    "print(train_logits[0])\n",
    "\n",
    "# Obtener el valor m√°ximo y m√≠nimo entre todas las salidas\n",
    "valor_maximo = np.max(train_logits)\n",
    "valor_minimo = np.min(train_logits)\n",
    "\n",
    "print(\"\\nValor m√°ximo entre todas las salidas:\", valor_maximo)\n",
    "print(\"Valor m√≠nimo entre todas las salidas:\", valor_minimo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eda7ba0",
   "metadata": {},
   "source": [
    "##### ¬øQu√© esperar de la salida?\n",
    "\n",
    "- Un array de 10 valores para logits[0], correspondientes a las 10 clases posibles.\n",
    "- Valores fuera del rango [0, 1], confirmando que **no son probabilidades**.\n",
    "- M√°ximos y m√≠nimos que podr√≠an estar bastante alejados de 0 o 1 (por ejemplo, negativos o mayores que 1).\n",
    "\n",
    "Si queremos poder interpretar las salidas, debemos **aplicar la funci√≥n Softmax para convertirlas en probabilidades**. Esta operaci√≥n transforma los valores en un rango entre 0 y 1, y asegura que la suma total sea igual a 1, lo cual es caracter√≠stico de una distribuci√≥n de probabilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbaeb28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidades para el primer ejemplo:\n",
      "[4.2198710e-11 1.1826308e-09 2.1591042e-08 1.6675794e-07 7.6881296e-10\n",
      " 2.2415340e-06 8.3009993e-10 6.9456242e-02 6.4860366e-08 9.3054128e-01]\n",
      "\n",
      "Suma de probabilidades (primeros 5 ejemplos):\n",
      "[1.        1.        1.0000001 1.0000001 1.       ]\n"
     ]
    }
   ],
   "source": [
    "# Aplicar softmax a todas las salidas\n",
    "train_pred = softmax(train_logits).numpy()\n",
    "\n",
    "# Mostrar las probabilidades del primer ejemplo\n",
    "print(\"Probabilidades para el primer ejemplo:\")\n",
    "print(train_pred[0])\n",
    "\n",
    "# Verificar que la suma de cada fila sea 1 (opcional)\n",
    "sum_train_pred = np.sum(train_pred, axis=1)\n",
    "\n",
    "# Mostrar suma de probabilidades de los primeros 5 ejemplos\n",
    "print(\"\\nSuma de probabilidades (primeros 5 ejemplos):\")\n",
    "print(sum_train_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3096fec4",
   "metadata": {},
   "source": [
    "\n",
    "Como se observa, los valores de salida se encuentran en el rango **[0, 1]**. \n",
    "\n",
    "Adem√°s, si sumamos las probabilidades correspondientes a un ejemplo, el resultado deber√≠a ser **1.0**, ya que representan una distribuci√≥n de probabilidad.\n",
    "\n",
    "(**Nota:** Se puede modificar el √≠ndice del ejemplo y verificar que, efectivamente, para cualquier caso, la suma de las probabilidades siempre da 1.0).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baf2cb0",
   "metadata": {},
   "source": [
    "#### ¬øC√≥mo obtener las categor√≠as estimadas?\n",
    "Para obtener que categor√≠a que se estim√≥ con el modelo para un ejemplo dado se debe seleccionar la categor√≠a m√°s probable. \n",
    "\n",
    "Para ello, es posible encontrar el √≠ndice de la salida con mayor probabilidad utilizando np.argmax(). \n",
    "\n",
    "A continuaci√≥n se muestran las categor√≠as estimadas y las reales para los 10 primeros ejemplos del dataset de testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc980ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Etiquetas estimadas vs etiquetas reales (primeros 10 ejemplos):\n",
      "Ejemplo 0: Estimada = 9, Real = 9\n",
      "Ejemplo 1: Estimada = 2, Real = 2\n",
      "Ejemplo 2: Estimada = 1, Real = 1\n",
      "Ejemplo 3: Estimada = 1, Real = 1\n",
      "Ejemplo 4: Estimada = 6, Real = 6\n",
      "Ejemplo 5: Estimada = 1, Real = 1\n",
      "Ejemplo 6: Estimada = 4, Real = 4\n",
      "Ejemplo 7: Estimada = 6, Real = 6\n",
      "Ejemplo 8: Estimada = 5, Real = 5\n",
      "Ejemplo 9: Estimada = 7, Real = 7\n"
     ]
    }
   ],
   "source": [
    "test_logits = model.predict(X_test)\n",
    "\n",
    "test_pred = softmax(test_logits)\n",
    "    \n",
    "# Obtener las categor√≠as predichas seleccionando el √≠ndice con la mayor probabilidad\n",
    "test_predicted_labels = np.argmax(test_pred, axis=1)\n",
    "\n",
    "# Mostrar las etiquetas predichas y reales para los primeros 10 ejemplos\n",
    "print(\"Etiquetas estimadas vs etiquetas reales (primeros 10 ejemplos):\")\n",
    "for i in range(10):\n",
    "    print(f\"Ejemplo {i}: Estimada = {test_predicted_labels[i]}, Real = {y_test[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4082bf95",
   "metadata": {},
   "source": [
    "### Evaluaci√≥n del modelo\n",
    "\n",
    "Para evaluar el desempe√±o del modelo de forma cuantitativa, vamos a calcular el **accuracy** tanto sobre el conjunto de entrenamiento como sobre el de testeo.\n",
    "Para ello, utilizaremos la funci√≥n **accuracy_score** del m√≥dulo sklearn.metrics, que compara las etiquetas verdaderas con las predicciones generadas por el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3300b224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
      "Accuracy en entrenamiento: 0.9564\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Accuracy en testeo: 0.8878\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predicciones en entrenamiento\n",
    "train_logits = model.predict(X_train)\n",
    "train_pred = np.argmax(softmax(train_logits).numpy(), axis=1)\n",
    "train_acc = accuracy_score(y_train, train_pred)\n",
    "print(f\"Accuracy en entrenamiento: {train_acc:.4f}\")\n",
    "\n",
    "# Predicciones en testeo\n",
    "test_logits = model.predict(X_test)\n",
    "test_pred = np.argmax(softmax(test_logits).numpy(), axis=1)\n",
    "test_acc = accuracy_score(y_test, test_pred)\n",
    "print(f\"Accuracy en testeo: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fa6edb",
   "metadata": {},
   "source": [
    "## Observaciones finales:\n",
    "\n",
    "Si todo sali√≥ bien, en este punto el modelo de red neuronal deber√≠a alcanzar un accuracy del >90% en el conjunto de entrenamiento y un poco menor en el conjunto de testeo, lo cual indica un buen desempe√±o general en la tarea de clasificaci√≥n multiclase. Sin embargo, habr√≠a que analizar la diferencia entre ambos valores porque puede sugerir un **ligero overfitting**, es decir, el modelo se ajust√≥ mejor a los datos de entrenamiento que a los datos nuevos. De cualquier forma, la generalizaci√≥n sigue siendo aceptable.\n",
    "\n",
    "Podr√≠a evaluarse el uso de t√©cnicas de regularizaci√≥n (como dropout o L2), aumento de datos o ajuste de hiperpar√°metros para reducir esta brecha y mejorar la robustez del modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
