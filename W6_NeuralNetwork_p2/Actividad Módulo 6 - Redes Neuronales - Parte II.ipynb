{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef5a4c2e-1082-4e49-91cd-c1ec2abb237e",
   "metadata": {},
   "source": [
    "# INTEGRANTES:\n",
    "#####            -GONZALO DANIEL GRECCO\n",
    "#####            -MAURICIO NICOL√ÅS MOLINA PICCO\n",
    "#####            -MAR√çA IN√âS BERDI√ëAS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a6b98d7",
   "metadata": {},
   "source": [
    "# M√≥dulo 6: Redes Neuronales - Parte II\n",
    "\n",
    "## Redes Neuronales para clasificaci√≥n multiclase\n",
    "\n",
    "En esta actividad vamos a aprender a desarrollar una red neuronal profunda para reconocimiento de im√°genes.\n",
    "\n",
    "Adem√°s, estudiaremos algunos detalles de implementaci√≥n que nos ayudar√°n a organizar mejor nuestro c√≥digo y hacerlo m√°s eficiente.\n",
    "\n",
    "Por otro lado, aprenderemos a utilizar **Callbacks** para detener el proceso de entrenamiento anticipadamente si se alcanza un objetivo deseado.\n",
    "\n",
    "Para ello, vamos a trabajar con un dataset provisto por Keras: **Fashion MNIST**. Este dataset consta de **70.000 im√°genes en escala de grises de 28x28 p√≠xeles**, pertenecientes a una de **10 clases de prendas de vestir** diferentes.\n",
    "\n",
    "El dataset est√° dividido en **60.000 im√°genes para entrenamiento y 10.000 para testeo**.\n",
    "\n",
    "Cada imagen representa una prenda de vestir de una de las siguientes categor√≠as:\n",
    "\n",
    "                                0. T-shirt/top\n",
    "                                1. Trouser\n",
    "                                2. Pullover\n",
    "                                3. Dress\n",
    "                                4. Coat\n",
    "                                5. Sandal\n",
    "                                6. Shirt\n",
    "                                7. Sneaker\n",
    "                                8. Bag\n",
    "                                9. Ankle boot \n",
    "\n",
    "Cada p√≠xel tiene un valor asociado entre 0 y 255 que indica su nivel de luminosidad u oscuridad (valores m√°s altos indican mayor oscuridad).\n",
    "\n",
    "El dataset tiene **785 columnas**, donde la primera corresponde al **label** (la categor√≠a de la prenda) y las 784 restantes representan los features, es decir, los valores de cada uno de los p√≠xeles de la imagen.\n",
    "\n",
    "La idea es utilizar este dataset para **reconocer prendas de vestir mediante una red neuronal profunda**, compuesta por varias capas (**layers**) y m√∫ltiples neuronas. Para ello, ser√° necesario definir un **modelo de clasificaci√≥n multiclase**.\n",
    "\n",
    "En primer lugar, vamos a **cargar el dataset en memoria**, dividi√©ndolo en conjunto de entrenamiento y conjunto de testeo, e imprimiremos sus dimensiones para confirmar que se haya cargado correctamente.\n",
    "\n",
    "\n",
    "### <font color='red'>**Actividad 1:**</font>\n",
    "**a)** Escribir un programa en Python para obtener, desde el framework Keras, **el dataset Fashion MNIST dividido en conjunto de entrenamiento (X_train, y_train) y conjunto de testeo (X_test, y_test)**.\n",
    "\n",
    "**AYUDA:** el dataset fashion_mnist se encuentra dentro de la libreria keras.datasets. Keras provee una forma de obtener el dataset dividido en entrenamiento y testeo con el m√©todo [.load_data() ](https://www.tensorflow.org/api_docs/python/tf/keras/datasets/fashion_mnist/load_data#expandable-1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4083004b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "\n",
    "# Carga del dataset (ya dividido en train y test)\n",
    "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "#Carga el dataset. load_data() devuelve dos tuplas: la primera (X_train, y_train) para entrenamiento y la segunda (X_test, y_test) para testeo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9c8ec82",
   "metadata": {},
   "source": [
    "**b)** Imprimir las **dimensiones** de todos los datasets (X_train, y_train, X_test, y test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c7516835",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Dimensiones (shapes) ---\n",
      "X_train.shape: (60000, 28, 28)\n",
      "y_train.shape: (60000,)\n",
      "X_test.shape:  (10000, 28, 28)\n",
      "y_test.shape:  (10000,)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Dimensiones (shapes) ---\")\n",
    "print(\"X_train.shape:\", X_train.shape)\n",
    "print(\"y_train.shape:\", y_train.shape)\n",
    "print(\"X_test.shape: \", X_test.shape)\n",
    "print(\"y_test.shape: \", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f7b640-217c-4102-9e1d-bbf53a3a8054",
   "metadata": {},
   "source": [
    "### El resultado de shape de X es (60000,28,28) significa que son:\n",
    "- 60000 muestras (imagenes)\n",
    "- 28x28 tamanio de imagenes\n",
    "- la otra dimension no se muestra porque es 1 (1 dimension para color) pero si fuera rgb tendria otra"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a7d6ad7",
   "metadata": {},
   "source": [
    "### <font color='red'>**Actividad 2:**</font>\n",
    "**a)** Imprimir dos im√°genes cualquiera utilizando la librer√≠a **matplotlib**.\n",
    "\n",
    "**AYUDA:** Recordemos que para imprimir una imagen con matplotlib se puede utilizar el metodo [.imshow(image)](https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.imshow.html#matplotlib-pyplot-imshow), siendo image el vector que contiene los 784 pixeles de la imagen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "56a5d318",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt #matplotlib es la biblioteca de graficos \n",
    "\n",
    "# Mostrar la primera imagen de entrenamiento\n",
    "plt.subplot(1, 2, 1)                # 1 fila, 2 columnas, primer gr√°fico\n",
    "plt.imshow(X_train[0], cmap=\"gray\") # X_train[0] es una matriz 28x28\n",
    "plt.title(f\"Etiqueta: {y_train[0]}\")\n",
    "plt.axis(\"off\")                     \n",
    "#plt.axis(\"off\") quita los ejes para que se vea m√°s limpio\n",
    "\n",
    "# Mostrar la segunda imagen de entrenamiento\n",
    "plt.subplot(1, 2, 2)                # 1 fila, 2 columnas, segundo gr√°fico\n",
    "plt.imshow(X_train[1], cmap=\"gray\") # X_train[1] es otra imagen\n",
    "plt.title(f\"Etiqueta: {y_train[1]}\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6f20b58",
   "metadata": {},
   "source": [
    "### <font color='red'>**Actividad 3:**</font>\n",
    "**a)** **Normalizar los valores de los features** en los datasets de entrenamiento y testeo (X_train y X_test) dividiendo los valores de los pixeles por 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c828b4c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rango X_train: min = 0.0 , max = 1.0\n",
      "Rango X_test:  min = 0.0 , max = 1.0\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Los p√≠xeles en Fashion MNIST van de 0 a 255 (uint8).\n",
    "Al dividir entre 255, los llevamos al rango [0, 1], lo que hace que el entrenamiento sea m√°s estable y eficiente.\n",
    "\"\"\"\n",
    "#astype(\"float32\") convierte los pixeles enteros a n√∫meros decimales\n",
    "X_train = X_train.astype(\"float32\") / 255.0 \n",
    "X_test  = X_test.astype(\"float32\") / 255.0\n",
    "\n",
    "# Verificamos resultados\n",
    "print(\"Rango X_train: min =\", X_train.min(), \", max =\", X_train.max())\n",
    "print(\"Rango X_test:  min =\", X_test.min(),  \", max =\", X_test.max())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6993e0b",
   "metadata": {},
   "source": [
    "### Callbacks\n",
    "\n",
    "Los Callbacks de Keras son objetos que ejecutan acciones en distintas etapas del proceso de entrenamiento (por ejemplo, al comienzo o al final de cada epoch). Generalmente, se utilizan para escribir registros (logs) de monitoreo, guardar el modelo en disco peri√≥dicamente, detener el entrenamiento anticipadamente, entre otras funciones.\n",
    "\n",
    "El siguiente c√≥digo muestra c√≥mo crear un Callback personalizado en TensorFlow/Keras que detiene el entrenamiento cuando se alcanza un valor m√°ximo de precisi√≥n definido previamente:\n",
    "\n",
    "```\n",
    "class callbacks(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if logs.get(\"accuracy\") > MAX_ACC:\n",
    "            self.model.stop_training = True\n",
    "```\n",
    "\n",
    "Este tipo de callback se pasa como par√°metro al m√©todo .fit() mediante el argumento callbacks.\n",
    "\n",
    "### <font color='red'>**Actividad 4:**</font>\n",
    "**a)** Crear una clase **Callback** que detenga el proceso de entrenamiento al finalizar un epoch si se alcanza un valor de accuracy igual o superior a 0.95, e imprima el siguiente mensaje de aviso:\n",
    "\n",
    "\t‚ÄúSe alcanz√≥ el m√°ximo de precisi√≥n y, por lo tanto, se cancel√≥ el proceso de entrenamiento.‚Äù\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bf9cac2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "# Definici√≥n de Callback personalizado\n",
    "class EarlyStopAtAcc(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        max_accuracy = 0.95\n",
    "        acc = logs.get(\"accuracy\")\n",
    "        if acc is not None and acc >= max_accuracy:\n",
    "            print(\"\\nSe alcanz√≥ el m√°ximo de precisi√≥n y, por lo tanto, se cancel√≥ el proceso de entrenamiento.\")\n",
    "            self.model.stop_training = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb5cf506",
   "metadata": {},
   "source": [
    "### Ordenando el c√≥digo\n",
    "Ahora que tenemos los datasets de entrenamiento y testeo normalizados, y hemos observado algunos ejemplos, vamos a crear el modelo, compilarlo y entrenarlo.\n",
    "\n",
    "Para ello, definiremos un m√©todo que re√∫na todo el proceso completo:\n",
    "1. Obtener el dataset de entrenamiento y de testeo (resuelto en Actividad 1.a.)\n",
    "2. Normalizar los features de entrenamiento y testeo (resuelto en Actividad 3.)\n",
    "3. Crear el modelo en Keras\n",
    "4. Compilar el modelo (.compile(...))\n",
    "5. Ajustar o entrenar (.fit(...)) el modelo pasandole el callback creado y almacenando el historial del proceso de entrenamiento.\n",
    "6. Retornar el historial del proceso de entrenamiento y el modelo creado.\n",
    "\n",
    "#### üîß Creaci√≥n del modelo\n",
    "\n",
    "Vamos a construir una red neuronal con cuatro capas ocultas:\n",
    "- La primera con **512 neuronas**,\n",
    "- La segunda con **256 neuronas**,\n",
    "- La tercera con **128 neuronas**,\n",
    "- La cuarta con **64 neuronas**.\n",
    "\n",
    "Como se trata de un problema de **clasificaci√≥n multiclase**, al final del modelo utilizaremos la funci√≥n de activaci√≥n **softmax**. Sin embargo, implementaremos la **versi√≥n mejorada** vista en el apunte: la √∫ltima capa tendr√° activaci√≥n **lineal**, y la funci√≥n **softmax** se aplicar√° luego, por fuera del modelo.\n",
    "\n",
    "Adem√°s, como estamos trabajando con im√°genes, la primera capa de nuestra red debe ser una capa Flatten(), que transforma cada imagen 28x28 en un vector de 784 elementos.\n",
    "\n",
    "#### ‚öôÔ∏è Compilaci√≥n del modelo\n",
    "\n",
    "Al compilar el modelo:\n",
    "- Usaremos el optimizador **Adam** (optimizer='adam')\n",
    "- Como m√©trica de evaluaci√≥n, emplearemos **accuracy** (metrics=['accuracy'])\n",
    "- Usaremos *SparseCategoricalCrossentropy(from_logits=True)* como funci√≥n de p√©rdida ya que estamos utilizando logits como salida (activaci√≥n lineal en la √∫ltima capa)\n",
    "\n",
    "#### üèãÔ∏è Entrenamiento del modelo\n",
    "\n",
    "Al entrenar el modelo con .fit(), le pasaremos:\n",
    "- Le pasaremos el **callback personalizado** creado anteriormente (callbacks=[myCallback])\n",
    "- Definiremos la cantidad de **epochs en 100** (epochs=100)\n",
    "\n",
    "#### üìà Historial del entrenamiento\n",
    "\n",
    "El historial del proceso es devuelto por el m√©todo .fit() como un objeto History. Este objeto guarda, en su atributo .history, los registros de los valores de error y las m√©tricas obtenidas en cada epoch.\n",
    "\n",
    "\n",
    "### <font color='red'>**Actividad 5:**</font>\n",
    "**a)** Crear un m√©todo llamado train_fashion_mnist() que englobe los seis pasos mencionados anteriormente. Notar que algunos de estos pasos ya fueron resueltos en ejercicios anteriores, por lo tanto, simplemente debemos **copiar las l√≠neas de c√≥digo correspondientes dentro de este nuevo m√©todo** para integrarlos al flujo completo de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fde0f631",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.nn import softmax\n",
    "\n",
    "# Callback personalizado que detiene el entrenamiento al alcanzar 95% de accuracy\n",
    "class EarlyStopAtAcc(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        logs = logs or {}\n",
    "        acc = logs.get(\"accuracy\")\n",
    "        if acc is not None and acc >= 0.95:\n",
    "            print(\"\\nSe alcanz√≥ el m√°ximo de precisi√≥n y, por lo tanto, se cancel√≥ el proceso de entrenamiento.\")\n",
    "            self.model.stop_training = True\n",
    "\n",
    "def train_fashion_mnist():\n",
    "\n",
    "    # Creamos un objeto de la clase callbacks creada anteriormente\n",
    "    myCallback = EarlyStopAtAcc()\n",
    "    \n",
    "    # 1. Obtener el dataset de entrenamiento y de testeo (resuelto en Ejercicio 1) a.)\n",
    "    (X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
    "    \n",
    "    # 2. Normalizar los features de entrenamiento y testeo (resuelto en Ejercicio 3.)\n",
    "    X_train = X_train.astype(\"float32\") / 255.0\n",
    "    X_test  = X_test.astype(\"float32\") / 255.0\n",
    "    \n",
    "    # 3. Crear el modelo en Keras\n",
    "    model = models.Sequential([\n",
    "        layers.Flatten(input_shape=(28, 28)),   # Aplana la imagen 28x28 en vector 784\n",
    "        layers.Dense(512, activation=\"relu\"),\n",
    "        layers.Dense(256, activation=\"relu\"),\n",
    "        layers.Dense(128, activation=\"relu\"),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(10, activation=\"linear\")   # salida lineal\n",
    "    ])\n",
    "    \n",
    "    # 4. Compilar el modelo (.compile(...))\n",
    "    model.compile(\n",
    "        optimizer=\"adam\",\n",
    "        loss=SparseCategoricalCrossentropy(from_logits=True), \n",
    "        metrics=[\"accuracy\"]\n",
    "    ) #Cuando from_logits=True, Keras aplica internamente un softmax a los logits antes de calcular la entrop√≠a cruzada. \n",
    "        #De esta forma, no necesitamos poner activation=\"softmax\" dentro del modelo.\n",
    "    \n",
    "    # 5. Ajustar o entrenar (.fit(...)) el modelo pasandole el callback creado y almacenando el historial del proceso de entrenamiento.\n",
    "    history = model.fit(\n",
    "        X_train, y_train,\n",
    "        epochs=100,\n",
    "        callbacks=[myCallback],\n",
    "        validation_data=(X_test, y_test),\n",
    "        verbose=2\n",
    "    )\n",
    "    \n",
    "    # 6.Retornar el historial del proceso de entrenamiento.\n",
    "    return history.history, model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ff64da4",
   "metadata": {},
   "source": [
    "Ahora que tenemos un m√©todo capaz de realizar todo el proceso completo, **lo √∫nico que resta es llamar a dicho m√©todo** para obtener el objeto history y el model.\n",
    "\n",
    "El entrenamiento deber√≠a finalizar aproximadamente en el **epoch 35**, si se alcanza el nivel de precisi√≥n definido en el callback."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "77794dfd",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ezequiel\\AppData\\Local\\Packages\\PythonSoftwareFoundation.Python.3.11_qbz5n2kfra8p0\\LocalCache\\local-packages\\Python311\\site-packages\\keras\\src\\layers\\reshaping\\flatten.py:37: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1875/1875 - 17s - 9ms/step - accuracy: 0.8207 - loss: 0.4926 - val_accuracy: 0.8575 - val_loss: 0.3928\n",
      "Epoch 2/100\n",
      "1875/1875 - 14s - 8ms/step - accuracy: 0.8641 - loss: 0.3701 - val_accuracy: 0.8660 - val_loss: 0.3719\n",
      "Epoch 3/100\n",
      "1875/1875 - 14s - 7ms/step - accuracy: 0.8774 - loss: 0.3340 - val_accuracy: 0.8597 - val_loss: 0.3933\n",
      "Epoch 4/100\n",
      "1875/1875 - 13s - 7ms/step - accuracy: 0.8869 - loss: 0.3076 - val_accuracy: 0.8684 - val_loss: 0.3591\n",
      "Epoch 5/100\n",
      "1875/1875 - 13s - 7ms/step - accuracy: 0.8921 - loss: 0.2905 - val_accuracy: 0.8773 - val_loss: 0.3449\n",
      "Epoch 6/100\n",
      "1875/1875 - 14s - 7ms/step - accuracy: 0.8982 - loss: 0.2730 - val_accuracy: 0.8685 - val_loss: 0.3627\n",
      "Epoch 7/100\n",
      "1875/1875 - 14s - 8ms/step - accuracy: 0.9017 - loss: 0.2625 - val_accuracy: 0.8813 - val_loss: 0.3358\n",
      "Epoch 8/100\n",
      "1875/1875 - 14s - 7ms/step - accuracy: 0.9066 - loss: 0.2513 - val_accuracy: 0.8787 - val_loss: 0.3430\n",
      "Epoch 9/100\n",
      "1875/1875 - 14s - 7ms/step - accuracy: 0.9076 - loss: 0.2427 - val_accuracy: 0.8838 - val_loss: 0.3384\n",
      "Epoch 10/100\n",
      "1875/1875 - 14s - 7ms/step - accuracy: 0.9125 - loss: 0.2329 - val_accuracy: 0.8833 - val_loss: 0.3527\n",
      "Epoch 11/100\n",
      "1875/1875 - 14s - 7ms/step - accuracy: 0.9146 - loss: 0.2249 - val_accuracy: 0.8758 - val_loss: 0.3822\n",
      "Epoch 12/100\n",
      "1875/1875 - 14s - 7ms/step - accuracy: 0.9183 - loss: 0.2169 - val_accuracy: 0.8873 - val_loss: 0.3326\n",
      "Epoch 13/100\n",
      "1875/1875 - 21s - 11ms/step - accuracy: 0.9192 - loss: 0.2103 - val_accuracy: 0.8887 - val_loss: 0.3592\n",
      "Epoch 14/100\n",
      "1875/1875 - 13s - 7ms/step - accuracy: 0.9233 - loss: 0.2044 - val_accuracy: 0.8901 - val_loss: 0.3751\n",
      "Epoch 15/100\n",
      "1875/1875 - 13s - 7ms/step - accuracy: 0.9247 - loss: 0.1991 - val_accuracy: 0.8804 - val_loss: 0.3783\n",
      "Epoch 16/100\n",
      "1875/1875 - 13s - 7ms/step - accuracy: 0.9268 - loss: 0.1939 - val_accuracy: 0.8900 - val_loss: 0.3581\n",
      "Epoch 17/100\n",
      "1875/1875 - 14s - 7ms/step - accuracy: 0.9293 - loss: 0.1881 - val_accuracy: 0.8935 - val_loss: 0.3774\n",
      "Epoch 18/100\n",
      "1875/1875 - 14s - 7ms/step - accuracy: 0.9288 - loss: 0.1826 - val_accuracy: 0.8879 - val_loss: 0.3739\n",
      "Epoch 19/100\n",
      "1875/1875 - 14s - 7ms/step - accuracy: 0.9334 - loss: 0.1770 - val_accuracy: 0.8910 - val_loss: 0.3709\n",
      "Epoch 20/100\n",
      "1875/1875 - 14s - 7ms/step - accuracy: 0.9334 - loss: 0.1749 - val_accuracy: 0.8906 - val_loss: 0.3992\n",
      "Epoch 21/100\n",
      "1875/1875 - 14s - 8ms/step - accuracy: 0.9352 - loss: 0.1699 - val_accuracy: 0.8956 - val_loss: 0.3822\n",
      "Epoch 22/100\n",
      "1875/1875 - 14s - 7ms/step - accuracy: 0.9377 - loss: 0.1639 - val_accuracy: 0.8928 - val_loss: 0.3726\n",
      "Epoch 23/100\n",
      "1875/1875 - 14s - 7ms/step - accuracy: 0.9386 - loss: 0.1601 - val_accuracy: 0.8973 - val_loss: 0.4024\n",
      "Epoch 24/100\n",
      "1875/1875 - 13s - 7ms/step - accuracy: 0.9412 - loss: 0.1544 - val_accuracy: 0.8933 - val_loss: 0.4052\n",
      "Epoch 25/100\n",
      "1875/1875 - 13s - 7ms/step - accuracy: 0.9411 - loss: 0.1543 - val_accuracy: 0.8949 - val_loss: 0.3979\n",
      "Epoch 26/100\n",
      "1875/1875 - 13s - 7ms/step - accuracy: 0.9433 - loss: 0.1494 - val_accuracy: 0.8951 - val_loss: 0.4299\n",
      "Epoch 27/100\n",
      "1875/1875 - 14s - 7ms/step - accuracy: 0.9438 - loss: 0.1498 - val_accuracy: 0.8919 - val_loss: 0.4662\n",
      "Epoch 28/100\n",
      "1875/1875 - 13s - 7ms/step - accuracy: 0.9447 - loss: 0.1472 - val_accuracy: 0.8966 - val_loss: 0.4448\n",
      "Epoch 29/100\n",
      "1875/1875 - 13s - 7ms/step - accuracy: 0.9467 - loss: 0.1414 - val_accuracy: 0.8960 - val_loss: 0.4470\n",
      "Epoch 30/100\n",
      "1875/1875 - 14s - 7ms/step - accuracy: 0.9472 - loss: 0.1385 - val_accuracy: 0.8947 - val_loss: 0.4470\n",
      "Epoch 31/100\n",
      "1875/1875 - 13s - 7ms/step - accuracy: 0.9484 - loss: 0.1357 - val_accuracy: 0.8963 - val_loss: 0.4723\n",
      "Epoch 32/100\n",
      "1875/1875 - 13s - 7ms/step - accuracy: 0.9485 - loss: 0.1361 - val_accuracy: 0.8935 - val_loss: 0.4714\n",
      "Epoch 33/100\n",
      "\n",
      "Se alcanz√≥ el m√°ximo de precisi√≥n y, por lo tanto, se cancel√≥ el proceso de entrenamiento.\n",
      "1875/1875 - 13s - 7ms/step - accuracy: 0.9510 - loss: 0.1306 - val_accuracy: 0.8953 - val_loss: 0.4704\n"
     ]
    }
   ],
   "source": [
    "history, model = train_fashion_mnist()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8ec3d74",
   "metadata": {},
   "source": [
    "Hay que tener en cuenta que, en el modelo creado, **a√∫n no se ha aplicado la funci√≥n softmax**, por lo que las salidas **no representan probabilidades**. Es decir, los valores de salida pueden estar en el rango **[-‚àû, +‚àû]**.\n",
    "\n",
    "A continuaci√≥n, vamos a observar los valores de salida para el **primer ejemplo** del conjunto de entrenamiento. Adem√°s, analizaremos **los valores m√°ximos y m√≠nimos** de todas las salidas para confirmar que **no se trata de probabilidades**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6aede106",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 3ms/step\n",
      "Salidas sin softmax para el primer ejemplo:\n",
      "[-3125.329   -4231.3447  -6613.497   -8286.363   -4685.825   -2365.0823\n",
      " -6052.7036    852.36694 -1734.9478   3653.459  ]\n",
      "\n",
      "Valor m√°ximo entre todas las salidas: 86792.7\n",
      "Valor m√≠nimo entre todas las salidas: -264602.38\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Obtener las salidas del modelo (logits) sin aplicar softmax\n",
    "train_logits = model.predict(X_train)\n",
    "\n",
    "# Mostrar los valores de salida para el primer ejemplo\n",
    "print(\"Salidas sin softmax para el primer ejemplo:\")\n",
    "print(train_logits[0])\n",
    "\n",
    "# Obtener el valor m√°ximo y m√≠nimo entre todas las salidas\n",
    "valor_maximo = np.max(train_logits)\n",
    "valor_minimo = np.min(train_logits)\n",
    "\n",
    "print(\"\\nValor m√°ximo entre todas las salidas:\", valor_maximo)\n",
    "print(\"Valor m√≠nimo entre todas las salidas:\", valor_minimo)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4eda7ba0",
   "metadata": {},
   "source": [
    "##### ¬øQu√© esperar de la salida?\n",
    "\n",
    "- Un array de 10 valores para logits[0], correspondientes a las 10 clases posibles.\n",
    "- Valores fuera del rango [0, 1], confirmando que **no son probabilidades**.\n",
    "- M√°ximos y m√≠nimos que podr√≠an estar bastante alejados de 0 o 1 (por ejemplo, negativos o mayores que 1).\n",
    "\n",
    "Si queremos poder interpretar las salidas, debemos **aplicar la funci√≥n Softmax para convertirlas en probabilidades**. Esta operaci√≥n transforma los valores en un rango entre 0 y 1, y asegura que la suma total sea igual a 1, lo cual es caracter√≠stico de una distribuci√≥n de probabilidad."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "dbaeb28b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Probabilidades para el primer ejemplo:\n",
      "[4.2198710e-11 1.1826308e-09 2.1591042e-08 1.6675794e-07 7.6881296e-10\n",
      " 2.2415340e-06 8.3009993e-10 6.9456242e-02 6.4860366e-08 9.3054128e-01]\n",
      "\n",
      "Suma de probabilidades (primeros 5 ejemplos):\n",
      "[1.        1.        1.0000001 1.0000001 1.       ]\n"
     ]
    }
   ],
   "source": [
    "# Aplicar softmax a todas las salidas\n",
    "train_pred = softmax(train_logits).numpy()\n",
    "\n",
    "# Mostrar las probabilidades del primer ejemplo\n",
    "print(\"Probabilidades para el primer ejemplo:\")\n",
    "print(train_pred[0])\n",
    "\n",
    "# Verificar que la suma de cada fila sea 1 (opcional)\n",
    "sum_train_pred = np.sum(train_pred, axis=1)\n",
    "\n",
    "# Mostrar suma de probabilidades de los primeros 5 ejemplos\n",
    "print(\"\\nSuma de probabilidades (primeros 5 ejemplos):\")\n",
    "print(sum_train_pred[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3096fec4",
   "metadata": {},
   "source": [
    "\n",
    "Como se observa, los valores de salida se encuentran en el rango **[0, 1]**. \n",
    "\n",
    "Adem√°s, si sumamos las probabilidades correspondientes a un ejemplo, el resultado deber√≠a ser **1.0**, ya que representan una distribuci√≥n de probabilidad.\n",
    "\n",
    "(**Nota:** Se puede modificar el √≠ndice del ejemplo y verificar que, efectivamente, para cualquier caso, la suma de las probabilidades siempre da 1.0).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baf2cb0",
   "metadata": {},
   "source": [
    "#### ¬øC√≥mo obtener las categor√≠as estimadas?\n",
    "Para obtener que categor√≠a que se estim√≥ con el modelo para un ejemplo dado se debe seleccionar la categor√≠a m√°s probable. \n",
    "\n",
    "Para ello, es posible encontrar el √≠ndice de la salida con mayor probabilidad utilizando np.argmax(). \n",
    "\n",
    "A continuaci√≥n se muestran las categor√≠as estimadas y las reales para los 10 primeros ejemplos del dataset de testeo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cc980ad7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Etiquetas estimadas vs etiquetas reales (primeros 10 ejemplos):\n",
      "Ejemplo 0: Estimada = 9, Real = 9\n",
      "Ejemplo 1: Estimada = 2, Real = 2\n",
      "Ejemplo 2: Estimada = 1, Real = 1\n",
      "Ejemplo 3: Estimada = 1, Real = 1\n",
      "Ejemplo 4: Estimada = 6, Real = 6\n",
      "Ejemplo 5: Estimada = 1, Real = 1\n",
      "Ejemplo 6: Estimada = 4, Real = 4\n",
      "Ejemplo 7: Estimada = 6, Real = 6\n",
      "Ejemplo 8: Estimada = 5, Real = 5\n",
      "Ejemplo 9: Estimada = 7, Real = 7\n"
     ]
    }
   ],
   "source": [
    "test_logits = model.predict(X_test)\n",
    "\n",
    "test_pred = softmax(test_logits)\n",
    "    \n",
    "# Obtener las categor√≠as predichas seleccionando el √≠ndice con la mayor probabilidad\n",
    "test_predicted_labels = np.argmax(test_pred, axis=1)\n",
    "\n",
    "# Mostrar las etiquetas predichas y reales para los primeros 10 ejemplos\n",
    "print(\"Etiquetas estimadas vs etiquetas reales (primeros 10 ejemplos):\")\n",
    "for i in range(10):\n",
    "    print(f\"Ejemplo {i}: Estimada = {test_predicted_labels[i]}, Real = {y_test[i]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4082bf95",
   "metadata": {},
   "source": [
    "### Evaluaci√≥n del modelo\n",
    "\n",
    "Para evaluar el desempe√±o del modelo de forma cuantitativa, vamos a calcular el **accuracy** tanto sobre el conjunto de entrenamiento como sobre el de testeo.\n",
    "Para ello, utilizaremos la funci√≥n **accuracy_score** del m√≥dulo sklearn.metrics, que compara las etiquetas verdaderas con las predicciones generadas por el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "3300b224",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1875/1875\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 2ms/step\n",
      "Accuracy en entrenamiento: 0.9564\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step\n",
      "Accuracy en testeo: 0.8878\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Predicciones en entrenamiento\n",
    "train_logits = model.predict(X_train)\n",
    "train_pred = np.argmax(softmax(train_logits).numpy(), axis=1)\n",
    "train_acc = accuracy_score(y_train, train_pred)\n",
    "print(f\"Accuracy en entrenamiento: {train_acc:.4f}\")\n",
    "\n",
    "# Predicciones en testeo\n",
    "test_logits = model.predict(X_test)\n",
    "test_pred = np.argmax(softmax(test_logits).numpy(), axis=1)\n",
    "test_acc = accuracy_score(y_test, test_pred)\n",
    "print(f\"Accuracy en testeo: {test_acc:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fa6edb",
   "metadata": {},
   "source": [
    "## Observaciones finales:\n",
    "\n",
    "Si todo sali√≥ bien, en este punto el modelo de red neuronal deber√≠a alcanzar un accuracy del >90% en el conjunto de entrenamiento y un poco menor en el conjunto de testeo, lo cual indica un buen desempe√±o general en la tarea de clasificaci√≥n multiclase. Sin embargo, habr√≠a que analizar la diferencia entre ambos valores porque puede sugerir un **ligero overfitting**, es decir, el modelo se ajust√≥ mejor a los datos de entrenamiento que a los datos nuevos. De cualquier forma, la generalizaci√≥n sigue siendo aceptable.\n",
    "\n",
    "Podr√≠a evaluarse el uso de t√©cnicas de regularizaci√≥n (como dropout o L2), aumento de datos o ajuste de hiperpar√°metros para reducir esta brecha y mejorar la robustez del modelo."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
