{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1fbadd0e",
   "metadata": {},
   "source": [
    "# Módulo 8: SVM\n",
    "\n",
    "## Clasificación binaria: ¿maligno o benigno?\n",
    "\n",
    "Para esta actividad, vamos a utilizar un dataset que se encuentra disponible entre los conjuntos de prueba de la librería scikit-learn: **Breast Cancer Dataset**.\n",
    "\n",
    "Se trata de un dataset diseñado para realizar clasificación binaria. Contiene un total de 569 ejemplos, cada uno con 30 features, y 2 clases posibles: **maligno** o **benigno**.\n",
    "\n",
    "El objetivo es, dada una nueva instancia del cual conocemos los features, podamos determinar a qué clase pertenece: **maligno** o **benigno**.\n",
    "\n",
    "### <font color='red'>**Actividad 1:**</font>\n",
    "\n",
    "**a)** Obtener el dataset de la librería Scikit-learn como un pandas Dataframe, almacenando los datos en una variable llamada *df_data* y los labels en otra variable llamada *df_labels*\n",
    "\n",
    "**Ayuda:** \n",
    "El [método de Scikit-Learn](https://scikit-learn.org/stable/modules/generated/sklearn.datasets.load_breast_cancer.html) para levantar el dataset requerido permite convertir la salida en un Dataframe de pandas con el parametro as_frame. Para realizar este ejercicio es necesario investigar en el sitio oficial de Scikit-Learn como se retornan los datos y los labels cuando este parametro está seteado en True."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1469c1dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "\n",
    "cancer_data = load_breast_cancer(as_frame=True)\n",
    "\n",
    "df_data = cancer_data.data\n",
    "\n",
    "df_labels = cancer_data.target"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdf48b70",
   "metadata": {},
   "source": [
    "**b)** Imprimir los 10 primeros ejemplo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d10ac8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a523734",
   "metadata": {},
   "source": [
    "**c)** Imprimir los 10 últimos ejemplos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c559d9ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_data.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc3c79a5",
   "metadata": {},
   "source": [
    "**d)** Imprimir los nombres de las columnas (features) del dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c2fadb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_data.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9a49444",
   "metadata": {},
   "source": [
    "**e)** Imprimir la cantidad de features que presenta el dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2e4abcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{31}\n"
     ]
    }
   ],
   "source": [
    "print(f\"Cantidad de features: {len(df_data.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ab2499f",
   "metadata": {},
   "source": [
    "**f)** Imprimir los últimos 10 labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25800a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_labels.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca3bccc5",
   "metadata": {},
   "source": [
    "**g)** Imprimir la cantidad de ejemplos (filas) de cada label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc0f0d76",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_labels.value_counts().sort_index())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f5b0967",
   "metadata": {},
   "source": [
    "#### Observaciones:\n",
    "El dataset presenta un total de 569 ejemplos, distribuidos de la siguiente manera:\n",
    "- Clase 1: 357 ejemplos (≈ 62.7%)\n",
    "- Clase 0: 212 ejemplos (≈ 37.3%)\n",
    "\n",
    "Esto indica que el dataset está **moderadamente desbalanceado**, ya que hay una diferencia significativa entre ambas clases (aproximadamente 25 puntos porcentuales). Aunque no es un desbalance extremo, puede afectar el desempeño de los modelos de clasificación, especialmente si se utiliza una métrica como el **accuracy**, que puede dar una falsa impresión de buen rendimiento al favorecer la clase mayoritaria."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80b4dc6e",
   "metadata": {},
   "source": [
    "### Visualización de los datos\n",
    "\n",
    "Ahora que exploramos la composición del dataset, incluyendo sus features y etiquetas, **vamos a analizar las relaciones entre algunos atributos seleccionados** de forma visual.\n",
    "\n",
    "Dado que el conjunto de datos contiene **30 features**, resulta imposible representar visualmente las relaciones en un espacio de 30 dimensiones. Por eso, seleccionamos un subconjunto representativo de 5 features:\n",
    "\n",
    "                'mean radius', 'mean texture', 'mean perimeter', 'mean area' y 'mean smoothness'\n",
    "\n",
    "Para explorar cómo se relacionan entre sí y con las clases, utilizaremos un **pairplot**, que permite visualizar las relaciones **por pares** de variables mediante gráficos de dispersión y distribuciones univariadas.\n",
    "\n",
    "Este análisis nos ayudará a identificar:\n",
    "- Si existe **separabilidad entre clases** en función de estas variables.\n",
    "- Si podría tener sentido aplicar un modelo como SVM, que busca encontrar un hiperplano que separe las clases en el espacio de características."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92783402",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "df = df_data\n",
    "df['label'] = df_labels\n",
    "sns.pairplot(df, hue='label', vars=['mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9043d7c3",
   "metadata": {},
   "source": [
    "En la **diagonal principal del pairplot** se muestran las distribuciones univariadas de cada feature, separadas por clase. Estas curvas permiten observar cómo se distribuye cada variable individualmente en cada clase:\n",
    "- Por ejemplo, en mean area o mean perimeter, se nota que la clase naranja (una de las clases) tiene valores generalmente más bajos que la clase azul, lo cual sugiere que estas variables podrían ser buenas para separar las clases.\n",
    "- En cambio, en mean smoothness, ambas clases tienen distribuciones bastante solapadas, lo que indica que este feature tiene menor capacidad discriminativa por sí solo.\n",
    "\n",
    "El resto de los gráficos muestran cómo se distribuyen los datos considerando únicamente **dos features a la vez**, ignorando los otros 28. Estos gráficos permiten observar si existe **separabilidad entre clases** en pares de variables.\n",
    "\n",
    "En general, se observa que hay cierta **separación entre las clases** usando los features seleccionados, aunque no es perfecta. Esto sugiere que **aplicar un modelo como SVM podría ser apropiado**. En particular, podría ser útil utilizar un **kernel no lineal** para capturar mejor los límites entre clases en las zonas donde hay solapamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c0c05b",
   "metadata": {},
   "source": [
    "## SVM no lineal con kernel sigmoideo\n",
    "\n",
    "Ahora que analizamos los datos y sus features vamos a crear varios modelos SVM, entrenarlos con nuestros datos y observar su rendimiento.\n",
    "\n",
    "Para ello, primero tenemos que dividir los datos en dataset de entrenamiento y dataset de testeo.\n",
    "\n",
    "### <font color='red'>**Actividad 2:**</font>\n",
    "\n",
    "**a)** Dividir los datos, reservando el **80 % para entrenamiento** y el **20 % para testeo**. Para ello, utilizar las variables df_data y df_labels creadas anteriormente. Almacenar los conjuntos resultantes en las siguientes variables:\n",
    "- X_train, X_test: para los datos de entrada (features)\n",
    "- y_train, y_test: para las etiquetas (labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ffab7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_data, df_labels, test_size=0.2, random_state=42, stratify=df_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9db5ba60",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('El tamaño de X_train es:', X_train.shape)\n",
    "print('El tamaño de y_train es:', y_train.shape)\n",
    "print()\n",
    "print('El tamaño de X_test es:', X_test.shape)\n",
    "print('El tamaño de y_test es:', y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a0ae671",
   "metadata": {},
   "source": [
    "**b)** Importar el módulo correspondiente de Scikit-Learn para la creación de un modelo **SVM para clasificación**, y crear una instancia del mismo. En este caso, se utilizará un modelo **no lineal con kernel sigmoideo** (sigmoid)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32084a1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model = SVC(kernel='sigmoid', random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4aca367c",
   "metadata": {},
   "source": [
    "**c)** **Ajustar el modelo** con la función .fit() a los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2ebdf97",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acdd134e",
   "metadata": {},
   "source": [
    "### Evaluación del modelo SVM no lineal con kernel sigmoideo\n",
    "Ahora que tenemos el modelo SVM no lineal con kernel sigmoideo entrenado, vamos a realizar predicciones sobre el dataset de entrenamiento y observar el rendimiento del modelo, analizando la **matriz de confusión**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "276e27cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "y_train_predict = svc_model.predict(X_train)\n",
    "\n",
    "cm_train = np.array(confusion_matrix(y_train, y_train_predict, labels=[0,1]))\n",
    "\n",
    "confusion_matrix_train = pd.DataFrame(cm_train, index=['Maligno (Real)', 'Benigno (Real)'], columns=['Maligno (Estimado)', 'Benigno (Estimado)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92db98c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_train"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad34c3b1",
   "metadata": {},
   "source": [
    "La matriz de confusión muestra que el modelo comete muchos errores al clasificar casos malignos del **dataset de entrenamiento**:\n",
    "- Sólo 27 de los 167 casos malignos reales fueron clasificados correctamente, mientras que 140 fueron mal clasificados como benignos.\n",
    "- En los casos benignos, el modelo acierta en 180 de los 288 casos, pero clasifica erróneamente 108 como malignos.\n",
    "\n",
    "Veamos como lo hace en el **dataset de testeo**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "188a12d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict = svc_model.predict(X_test)\n",
    "\n",
    "cm_test = np.array(confusion_matrix(y_test, y_test_predict, labels=[0,1]))\n",
    "\n",
    "confusion_matrix_test = pd.DataFrame(cm_test, index=['Maligno (Real)', 'Benigno (Real)'], columns=['Maligno (Estimado)', 'Benigno (Estimado)'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9365f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_test"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2b06b8a",
   "metadata": {},
   "source": [
    "Esta matriz indica que el modelo tiene un **recall bajo para la clase maligna**, ya que **de 45 casos malignos reales, solo 8 fueron correctamente clasificados**, mientras que **37 fueron mal clasificados como benignos** (falsos negativos).\n",
    "\n",
    "En el caso de la clase benigna, el modelo tiene un mejor desempeño, con **48 verdaderos positivos** sobre 69 casos reales.\n",
    "\n",
    "Este resultado es **preocupante en contextos sensibles como el médico**, donde los falsos negativos pueden tener consecuencias graves. El modelo tiende a **subestimar la clase maligna**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b620adc6",
   "metadata": {},
   "source": [
    "A continuación, analizaremos algunas métricas, empezando por el **accuracy**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30895ac6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Accuracy:\",accuracy_score(y_test, y_test_predict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6e3133",
   "metadata": {},
   "source": [
    "Además, con Scikit-Learn podemos crear facilmente un **reporte de clasificación** para observar las distintas metricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7e8cc3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "\n",
    "print(classification_report(y_test, y_test_predict))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "981fd365",
   "metadata": {},
   "source": [
    "Como podemos ver, el modelo tiene un **accuracy muy bajo (≈ 39 %)** y un **desempeño deficiente en ambas clases**. En particular, clasifica mal los casos **malignos** (clase 0), con una **precisión de 0.19** y un **recall de 0.29**. Esto indica que el modelo **no es adecuado en su forma actual** y necesita mejoras. Por lo tanto, vamos a probar con un **kernel distinto**; en este caso, utilizaremos un **kernel polinomial**.\n",
    "\n",
    "## SVM no lineal con kernel polinomial\n",
    "Vamos a entrenar un modelo **SVM no lineal** utilizando un **kernel polinomial**, con el objetivo de mejorar la capacidad del modelo para capturar relaciones más complejas entre los datos que no son linealmente separables.\n",
    "\n",
    "### <font color='red'>**Actividad 3:**</font>\n",
    "\n",
    "**a)** Crear un **modelo SVM no lineal con kernel polinomial** y ajustarlo a los datos de entrenamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "348cc5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_poly_model = SVC(kernel='poly', random_state=42)\n",
    "\n",
    "svc_poly_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54820454",
   "metadata": {},
   "source": [
    "### Evaluación del modelo SVM no lineal con kernel polinomial\n",
    "Una vez creado el modelo y ajustado a los datos de entrenamiento vamos a analizar las predicciones.\n",
    "\n",
    "### <font color='red'>**Actividad 4:**</font>\n",
    "\n",
    "**a)** Evaluar el modelo en el **dataset de entrenamiento**, creando la **matriz de confusión**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b8a3a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict_poly = svc_poly_model.predict(X_train)\n",
    "\n",
    "cm_train_poly = np.array(confusion_matrix(y_train, y_train_predict_poly, labels=[0,1]))\n",
    "\n",
    "confusion_matrix_train_poly = pd.DataFrame(cm_train_poly, index=['Maligno (Real)', 'Benigno (Real)'], columns=['Maligno (Estimado)', 'Benigno (Estimado)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad6a0935",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_train_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "858b29ef",
   "metadata": {},
   "source": [
    "**b)** Evaluar el modelo en el **dataset de testeo**, creando la **matriz de confusión**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95285257",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict_poly = svc_poly_model.predict(X_test)\n",
    "\n",
    "cm_test_poly = np.array(confusion_matrix(y_test, y_test_predict_poly, labels=[0,1]))\n",
    "\n",
    "confusion_matrix_test_poly = pd.DataFrame(cm_test_poly, index=['Maligno (Real)', 'Benigno (Real)'],  columns=['Maligno (Estimado)', 'Benigno (Estimado)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "545daa9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_test_poly"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3315ea1",
   "metadata": {},
   "source": [
    "**c)** Imprimir el **Accuracy** para las predicciones en el **dataset de testeo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ed075eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy_poly = accuracy_score(y_test, y_test_predict_poly)\n",
    "print(f\"Accuracy: {accuracy_poly:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bad47674",
   "metadata": {},
   "source": [
    "**d)** Imprimir el **reporte de clasificación en testeo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "023515b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_test_predict_poly))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dd425b5",
   "metadata": {},
   "source": [
    "Si todo salió bien, en este punto nos daremos cuenta que utilizar el kernel polinomial fue una mejor decisión y que ahora tenemos un Accuracy mayor que 90%.\n",
    "\n",
    "Veamos que sucede si utilizamos un kernel lineal, es decir, SVM lineal.\n",
    "\n",
    "## SVM Lineal\n",
    "\n",
    "### <font color='red'>**Actividad 5:**</font>\n",
    "\n",
    "**a)** Crear **un modelo SVM lineal** y ajustarlo a los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0e03e6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "svc_linear_model = SVC(kernel='linear', random_state=42)\n",
    "\n",
    "svc_linear_model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c1f4366",
   "metadata": {},
   "source": [
    "### Evaluación del modelo SVM Lineal\n",
    "Una vez creado el modelo y ajustado a los datos de entrenamiento vamos a analizar las predicciones.\n",
    "\n",
    "### <font color='red'>**Actividad 6:**</font>\n",
    "\n",
    "**a)** Evaluar el modelo en el **dataset de entrenamiento**, creando la **matriz de confusión**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5b0e2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_predict_linear = svc_linear_model.predict(X_train)\n",
    "\n",
    "cm_train_linear = np.array(confusion_matrix(y_train, y_train_predict_linear, labels=[0,1]))\n",
    "\n",
    "confusion_matrix_train_linear = pd.DataFrame(cm_train_linear, index=['Maligno (Real)', 'Benigno (Real)'], columns=['Maligno (Estimado)', 'Benigno (Estimado)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0574ec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_train_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fa1a5ca",
   "metadata": {},
   "source": [
    "**b)** Evaluar el modelo en el **dataset de testeo**, creando la **matriz de confusión**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55cba384",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test_predict_linear = svc_linear_model.predict(X_test)\n",
    "\n",
    "cm_test_linear = np.array(confusion_matrix(y_test, y_test_predict_linear, labels=[0,1]))\n",
    "\n",
    "confusion_matrix_test_linear = pd.DataFrame(cm_test_linear, index=['Maligno (Real)', 'Benigno (Real)'], columns=['Maligno (Estimado)', 'Benigno (Estimado)'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c3724acd",
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix_test_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fac761e",
   "metadata": {},
   "source": [
    "**c)** Imprimir el **Accuracy** para las predicciones en el **dataset de testeo**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1dca46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "accuracy_linear = accuracy_score(y_test, y_test_predict_linear)\n",
    "print(f\"Accuracy: {accuracy_linear:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1947c71a",
   "metadata": {},
   "source": [
    "**d)** Imprimir el reporte de clasificación en testeo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb63582",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_test, y_test_predict_linear))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f00f0906",
   "metadata": {},
   "source": [
    "En este caso, deberiamos obtener un clasificador con un **Accuracy del 100% o muy cercano**. \n",
    "\n",
    "Naturalmente, esto no significa que hayamos creado un **modelo perfecto para la detección de cáncer**. En realidad, este dataset es un **conjunto de datos de ejemplo**, con una cantidad limitada de instancias, pensado principalmente para **fines educativos** y para aprender a utilizar distintos algoritmos de clasificación.\n",
    "\n",
    "Para llevar un modelo de este tipo a **producción real**, sería necesario contar con un volumen de datos mucho mayor, representativo y de calidad, así como entrenar modelos más complejos y realizar una validación rigurosa."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
